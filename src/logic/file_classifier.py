import os
import logging
import re
from typing import Optional, List, Dict

class FileClassifier:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†é¡ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹ã€‚
    ãƒ•ã‚¡ã‚¤ãƒ«åã‚„VLMï¼ˆVision-Language Modelï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒåŠ©æˆé‡‘ç”³è«‹æ›¸ã€å‹Ÿé›†è¦é …ã€ã‚ã‚‹ã„ã¯ç„¡é–¢ä¿‚ãªè³‡æ–™ã§ã‚ã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚
    """
    
    def __init__(self, gemini_client, vlm_model: str = "gemini-3-flash-preview"):
        """
        Args:
            gemini_client: Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
            vlm_model: ä½¿ç”¨ã™ã‚‹VLMãƒ¢ãƒ‡ãƒ«å
        """
        self.client = gemini_client
        self.vlm_model = vlm_model
    
    def _sanitize_grant_name(self, grant_name: str) -> str:
        """
        grant_nameã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒãƒ³ãƒ‰ï¼ˆã€Œãƒ‰ãƒ©ãƒ•ãƒˆã‚’ä½œæˆã—ã¦ã€ç­‰ï¼‰ã‚’é™¤å»ã™ã‚‹ã€‚
        """
        if not grant_name:
            return ""
        
        # é™¤å»ã™ã¹ããƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆã‚³ãƒãƒ³ãƒ‰ç³»ï¼‰
        remove_phrases = [
            'ã®ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ä½œæˆã—ã¦',
            'ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ä½œæˆã—ã¦',
            'ã®ãƒ‰ãƒ©ãƒ•ãƒˆä½œæˆ',
            'ãƒ‰ãƒ©ãƒ•ãƒˆä½œæˆ',
            'ã®ç”³è«‹æ›¸ã‚’æ›¸ã„ã¦',
            'ç”³è«‹æ›¸ã‚’æ›¸ã„ã¦',
            'ã‚’æ›¸ã„ã¦',
            'ã«ã¤ã„ã¦èª¿ã¹ã¦',
            'ã«ã¤ã„ã¦è©³ã—ã',
            'ã‚’èª¿ã¹ã¦',
            'ã®è©³ç´°',
        ]
        
        sanitized = grant_name
        for phrase in remove_phrases:
            sanitized = sanitized.replace(phrase, '')
        
        return sanitized.strip()
        
    def classify_format_file(self, filename: str, file_path: str = None, grant_name: str = None) -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”¨é€”ã‚’åˆ¤å®šã™ã‚‹ã€‚
        VLMã«ã‚ˆã‚‹åˆ¤å®šã‚’æœ€å„ªå…ˆã«è¡Œã„ã€ã§ããªã„å ´åˆã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®šã‚’è¡Œã†ã€‚
        
        Args:
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆVLMè§£æç”¨ï¼‰
            grant_name: åŠ©æˆé‡‘åï¼ˆVLMã§é–¢é€£æ€§ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ï¼‰
            
        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”¨é€”ã‚’ç¤ºã™æ–‡å­—åˆ—
        """
        fn_lower = filename.lower()
        
        # grant_nameã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒãƒ³ãƒ‰ã‚’é™¤å»ï¼‰
        if grant_name:
            grant_name = self._sanitize_grant_name(grant_name)
        
        # VLMã«ã‚ˆã‚‹åˆ¤å®šã‚’æœ€å„ªå…ˆã§å®Ÿæ–½ (User Request: Always use VLM if possible)
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã¨åŠ©æˆé‡‘åã¨ã®é–¢é€£æ€§ã‚’å³å¯†ã«ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãŸã‚
        if file_path and fn_lower.endswith(('.xlsx', '.xls', '.docx', '.doc', '.pdf')):
            vlm_result = self._classify_file_with_vlm(file_path, filename, grant_name)
            if vlm_result:
                return vlm_result
        
        # VLMåˆ¤å®šãŒã§ããªã‹ã£ãŸå ´åˆï¼ˆéå¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚¨ãƒ©ãƒ¼ç­‰ï¼‰ã®ã¿ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡æ˜“åˆ¤å®š
        logging.info(f"[DEBUG] VLMåˆ¤å®šãŒã§ããªã‹ã£ãŸãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡æ˜“åˆ¤å®š")

        # å‹Ÿé›†è¦é …ãƒ»å…¬å‹Ÿè¦é ˜ç³»ï¼ˆæœ€å„ªå…ˆã§åˆ¤å®šï¼‰
        if any(kw in fn_lower for kw in ['å‹Ÿé›†è¦é …', 'å…¬å‹Ÿè¦é ˜', 'å¿œå‹Ÿè¦é …', 'å…¬å‹Ÿè¦é …', 'å‹Ÿé›†æ¡ˆå†…', 'å…¬å‹Ÿæ¡ˆå†…', 'guidelines', 'requirements']):
            return "ğŸ“‹ å‹Ÿé›†è¦é …ï¼ˆå¿œå‹Ÿæ¡ä»¶ãƒ»å¯©æŸ»åŸºæº–ãŒè¨˜è¼‰ï¼‰"
        
        # äº¤ä»˜è¦ç¶±ãƒ»è¦ç¨‹ç³»
        if any(kw in fn_lower for kw in ['äº¤ä»˜è¦ç¶±', 'äº¤ä»˜è¦ç¨‹', 'å®Ÿæ–½è¦é ˜', 'ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³', 'guideline', 'æ‰‹å¼•ã', 'æ‰‹å¼•']):
            return "ğŸ“œ äº¤ä»˜è¦ç¶±ãƒ»ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼ˆãƒ«ãƒ¼ãƒ«ãƒ»è¦ç¨‹ï¼‰"
        
        # è¨˜å…¥ä¾‹ç³»ï¼ˆç”³è«‹æ›¸ã‚ˆã‚Šå…ˆã«åˆ¤å®šï¼‰
        if any(kw in fn_lower for kw in ['è¨˜å…¥ä¾‹', 'è¨˜è¼‰ä¾‹', 'ä½œæˆä¾‹', 'ã‚µãƒ³ãƒ—ãƒ«', 'sample', 'è¦‹æœ¬', 'ä¾‹', 'example']):
            return "ğŸ“– è¨˜å…¥ä¾‹ãƒ»ã‚µãƒ³ãƒ—ãƒ«ï¼ˆå‚è€ƒè³‡æ–™ï¼‰"
        
        # ç”³è«‹æ›¸ãƒ»æ§˜å¼ç³»
        if any(kw in fn_lower for kw in ['ç”³è«‹æ›¸', 'å¿œå‹Ÿæ›¸', 'æ§˜å¼', 'ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ', 'ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ', 'template', 'form', 'å±Šå‡º', 'èª¿æ›¸']):
            return "ğŸ“ ç”³è«‹æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè¨˜å…¥ãŒå¿…è¦ï¼‰"
        
        # äºˆç®—æ›¸ç³»
        if any(kw in fn_lower for kw in ['äºˆç®—', 'åæ”¯', 'çµŒè²»', 'budget', 'è¦‹ç©']):
            return "ğŸ’° äºˆç®—æ›¸ï¼ˆé‡‘é¡è¨˜å…¥ãŒå¿…è¦ï¼‰"
        
        # å ±å‘Šæ›¸ç³»
        if any(kw in fn_lower for kw in ['å ±å‘Š', 'report', 'å®Ÿç¸¾']):
            return "ğŸ“Š å ±å‘Šæ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"
        
        # äº‹æ¥­è¨ˆç”»ç³»
        if any(kw in fn_lower for kw in ['è¨ˆç”»', 'äº‹æ¥­', 'plan', 'project']):
            return "ğŸ“‹ äº‹æ¥­è¨ˆç”»æ›¸"
        
        # ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆç³»
        if any(kw in fn_lower for kw in ['ãƒã‚§ãƒƒã‚¯', 'check', 'ç¢ºèª', 'ãƒªã‚¹ãƒˆ']):
            return "âœ… ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ"
        
        return "ğŸ“„ é–¢é€£è³‡æ–™"
    
    def _classify_file_with_vlm(self, file_path: str, filename: str, grant_name: str = None) -> Optional[str]:
        """
        VLMã‚’ä½¿ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‹ã‚‰ç¨®åˆ¥ã‚’åˆ¤å®šã™ã‚‹ã€‚
        åŠ©æˆé‡‘åãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãã®åŠ©æˆé‡‘ã«é–¢é€£ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‚æ¤œè¨¼ã™ã‚‹ã€‚
        """
        if not self.client:
            return None
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’æŠ½å‡º
            content = self._extract_file_content_for_classification(file_path)
            if not content:
                return None
            
            # åŠ©æˆé‡‘åã®æ¤œè¨¼ã‚’è¿½åŠ  (Positive Matching - åŠ©æˆé‡‘åãƒ»äº¤ä»˜å›£ä½“åã®å«æœ‰ç¢ºèª)
            grant_name_check = ""
            if grant_name:
                # åŠ©æˆé‡‘åã‹ã‚‰ä¸»è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
                grant_keywords = self._extract_grant_keywords(grant_name)
                grant_name_check = f"""

ã€æœ€é‡è¦ã€‘åŠ©æˆé‡‘ã®é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ (Positive Matching):
å¯¾è±¡åŠ©æˆé‡‘å: {grant_name}
é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(grant_keywords)}

â–  åˆ¤å®šã®åŸºæœ¬åŸå‰‡ï¼ˆå¿…ãšå®ˆã‚‹ã“ã¨ï¼‰:
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã€Œå¯¾è±¡åŠ©æˆé‡‘ã€ã®æ­£è¦ã®ç”³è«‹æ›¸é¡ã§ã‚ã‚‹ãŸã‚ã«ã¯ã€
ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã«ä»¥ä¸‹ã®ã„ãšã‚Œã‹ãŒ**æ˜ç¢ºã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹**å¿…è¦ãŒã‚ã‚Šã¾ã™:

1. åŠ©æˆé‡‘åï¼ˆã€Œ{grant_name}ã€ã¾ãŸã¯ãã®ä¸€éƒ¨ï¼‰
2. åŠ©æˆé‡‘äº¤ä»˜å›£ä½“åãƒ»è²¡å›£åï¼ˆä¸Šè¨˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã„ãšã‚Œã‹ï¼‰
3. åŠ©æˆé‡‘ã®å…¬å‹Ÿå›å·ã‚„å¹´åº¦ã¨åˆã‚ã›ãŸè¨˜è¼‰

â–  NOT_RELATEDã¨åˆ¤å®šã™ã¹ãã‚±ãƒ¼ã‚¹:
- ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã«å¯¾è±¡åŠ©æˆé‡‘åãƒ»äº¤ä»˜å›£ä½“åãŒ**ä¸€åˆ‡è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„**
- åˆ¥ã®åŠ©æˆé‡‘åã€åˆ¥ã®è²¡å›£åãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹
- æ±ç”¨çš„ãªæ›¸é¡ï¼ˆä¼šè­°å®¤ç”³è¾¼æ›¸ã€å›£ä½“è¨­ç«‹å±Šã€å¥‘ç´„æ›¸ç­‰ï¼‰
- è²¡å›£ã®æ´»å‹•å ±å‘Šæ›¸ã€ãƒ‘ãƒ³ãƒ•ãƒ¬ãƒƒãƒˆç­‰ã®ã€Œèª­ã¿ç‰©ã€

â–  é‡è¦: 
ã€Œç”³è«‹æ›¸ã€ã€Œæ§˜å¼ã€ãªã©ã®å˜èªãŒã‚ã£ã¦ã‚‚ã€å¯¾è±¡åŠ©æˆé‡‘ã¨ã®ç´ä»˜ã‘ãŒãªã‘ã‚Œã°NOT_RELATEDã§ã™ã€‚
"""
            
            prompt = f"""
ã‚ãªãŸã¯åŠ©æˆé‡‘ç”³è«‹æ›¸é¡ã®åˆ†é¡å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã€å¯¾è±¡åŠ©æˆé‡‘ã®æ­£å¼ãªç”³è«‹é–¢é€£æ›¸é¡ã§ã‚ã‚‹ã‹å³å¯†ã«åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
{grant_name_check}

â–  ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:
ãƒ•ã‚¡ã‚¤ãƒ«å: {filename}

â–  ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼ˆå†’é ­éƒ¨åˆ†ï¼‰:
{content[:3000]}

â–  åˆ¤å®šæ‰‹é †:
1. ã¾ãšã€ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã«ã€Œ{grant_name}ã€ã¾ãŸã¯ãã®äº¤ä»˜å›£ä½“åãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
2. æ˜è¨˜ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ã€ä»¥ä¸‹ã®åˆ†é¡ã‚’è¡Œã†
3. æ˜è¨˜ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ NOT_RELATED

â–  åˆ†é¡é¸æŠè‚¢:
1. APPLICATION_FORM - å¯¾è±¡åŠ©æˆé‡‘ã®ç”³è«‹æ›¸/å¿œå‹Ÿæ›¸/æ§˜å¼ï¼ˆåŠ©æˆé‡‘åãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ï¼‰
2. GUIDELINES - å¯¾è±¡åŠ©æˆé‡‘ã®å‹Ÿé›†è¦é …/å…¬å‹Ÿè¦é ˜ï¼ˆåŠ©æˆé‡‘åãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ï¼‰
3. REGULATIONS - å¯¾è±¡åŠ©æˆé‡‘ã®äº¤ä»˜è¦ç¶±/ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
4. SAMPLE - å¯¾è±¡åŠ©æˆé‡‘ã®è¨˜å…¥ä¾‹/ã‚µãƒ³ãƒ—ãƒ«
5. BUDGET - å¯¾è±¡åŠ©æˆé‡‘ã®äºˆç®—æ›¸/çµŒè²»æ˜ç´°æ§˜å¼
6. REPORT - å¯¾è±¡åŠ©æˆé‡‘ã®å ±å‘Šæ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
7. PLAN - å¯¾è±¡åŠ©æˆé‡‘ã®äº‹æ¥­è¨ˆç”»æ›¸æ§˜å¼
8. CHECKLIST - å¯¾è±¡åŠ©æˆé‡‘ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
9. NOT_RELATED - å¯¾è±¡åŠ©æˆé‡‘ã¨ã®é–¢é€£æ€§ãªã—ï¼ˆåŠ©æˆé‡‘åãƒ»äº¤ä»˜å›£ä½“åãŒè¨˜è¼‰ã•ã‚Œã¦ã„ãªã„ã€ã¾ãŸã¯åˆ¥ã®åŠ©æˆé‡‘ï¼‰
10. OTHER - å¯¾è±¡åŠ©æˆé‡‘ã«é–¢é€£ã™ã‚‹ãŒã‚«ãƒ†ã‚´ãƒªä¸æ˜

å›ç­”ã¯é¸æŠè‚¢ã®è‹±èªã‚­ãƒ¼ï¼ˆä¾‹: APPLICATION_FORMï¼‰ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
            
            response = self.client.models.generate_content(
                model=self.vlm_model,
                contents=prompt
            )
            
            result = response.text.strip().upper()
            
            # åŠ©æˆé‡‘ã¨ã®é–¢é€£æ€§ãŒãªã„å ´åˆã¯OTHERã¨ã—ã¦æ‰±ã†
            if "NOT_RELATED" in result:
                logging.info(f"[FILE_CLASSIFIER] File '{filename}' is not related to grant '{grant_name}'")
                return "ğŸ“„ é–¢é€£è³‡æ–™ï¼ˆåˆ¥ã®åŠ©æˆé‡‘ã®å¯èƒ½æ€§ï¼‰"
            
            # çµæœã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
            mapping = {
                "APPLICATION_FORM": "ğŸ“ ç”³è«‹æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè¨˜å…¥ãŒå¿…è¦ï¼‰",
                "GUIDELINES": "ğŸ“‹ å‹Ÿé›†è¦é …ï¼ˆå¿œå‹Ÿæ¡ä»¶ãƒ»å¯©æŸ»åŸºæº–ãŒè¨˜è¼‰ï¼‰",
                "REGULATIONS": "ğŸ“œ äº¤ä»˜è¦ç¶±ãƒ»ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼ˆãƒ«ãƒ¼ãƒ«ãƒ»è¦ç¨‹ï¼‰",
                "SAMPLE": "ğŸ“– è¨˜å…¥ä¾‹ãƒ»ã‚µãƒ³ãƒ—ãƒ«ï¼ˆå‚è€ƒè³‡æ–™ï¼‰",
                "BUDGET": "ğŸ’° äºˆç®—æ›¸ï¼ˆé‡‘é¡è¨˜å…¥ãŒå¿…è¦ï¼‰",
                "REPORT": "ğŸ“Š å ±å‘Šæ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ",
                "PLAN": "ğŸ“‹ äº‹æ¥­è¨ˆç”»æ›¸",
                "CHECKLIST": "âœ… ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ",
            }
            
            return mapping.get(result, None)
            
        except Exception as e:
            logging.warning(f"[FILE_CLASSIFIER] VLM classification failed: {e}")
            return None
    
    def _extract_grant_keywords(self, grant_name: str) -> List[str]:
        """
        åŠ©æˆé‡‘åã‹ã‚‰ä¸»è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã™ã‚‹ã€‚
        """
        
        keywords = []
        
        # è²¡å›£åãƒ»æ³•äººåã®æŠ½å‡º (ä¾‹: ã€Œå…¬ç›Šè²¡å›£æ³•äººâ—‹â—‹è²¡å›£ã€â†’ã€Œâ—‹â—‹è²¡å›£ã€)
        org_patterns = [
            r'(?:å…¬ç›Š)?(?:ç¤¾å›£|è²¡å›£)æ³•äºº\s*([^\såŠ©æˆ]+)',  # è²¡å›£æ³•äººâ—‹â—‹
            r'([^\s]*è²¡å›£)',  # â—‹â—‹è²¡å›£
            r'([^\s]*åŸºé‡‘)',  # â—‹â—‹åŸºé‡‘
            r'([^\s]*å”ä¼š)',  # â—‹â—‹å”ä¼š
        ]
        
        for pattern in org_patterns:
            match = re.search(pattern, grant_name)
            if match:
                keywords.append(match.group(1))
        
        # åŠ©æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ åã®æŠ½å‡º
        program_patterns = [
            r'([^\s]*åŠ©æˆ(?:é‡‘|ãƒ—ãƒ­ã‚°ãƒ©ãƒ |äº‹æ¥­)?)',
            r'([^\s]*æ”¯æ´(?:é‡‘|ãƒ—ãƒ­ã‚°ãƒ©ãƒ |äº‹æ¥­)?)',
        ]
        
        for pattern in program_patterns:
            match = re.search(pattern, grant_name)
            if match:
                keywords.append(match.group(1))
        
        # é‡è¤‡ã‚’å‰Šé™¤ã—ã¤ã¤ã€å…ƒã®åŠ©æˆé‡‘åå…¨ä½“ã‚‚è¿½åŠ 
        if grant_name not in keywords:
            keywords.insert(0, grant_name)
        
        # é‡è¤‡ã‚’å‰Šé™¤
        seen = set()
        unique_keywords = []
        for kw in keywords:
            if kw not in seen:
                seen.add(kw)
                unique_keywords.append(kw)
        
        return unique_keywords[:5]  # æœ€å¤§5ã¤ã¾ã§
    
    def _extract_file_content_for_classification(self, file_path: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’æŠ½å‡ºï¼ˆåˆ†é¡ç”¨ï¼‰"""
        try:
            ext = os.path.splitext(file_path)[1].lower()
            
            if ext in ['.docx', '.doc']:
                from docx import Document
                doc = Document(file_path)
                texts = []
                for para in doc.paragraphs[:20]:  # æœ€åˆã®20æ®µè½
                    texts.append(para.text)
                for table in doc.tables[:3]:  # æœ€åˆã®3ãƒ†ãƒ¼ãƒ–ãƒ«
                    for row in table.rows:
                        texts.append(" | ".join([cell.text.strip() for cell in row.cells]))
                return "\n".join(texts)
            
            elif ext in ['.xlsx', '.xls']:
                import openpyxl
                wb = openpyxl.load_workbook(file_path, read_only=True)
                texts = []
                for sheet_name in wb.sheetnames[:2]:  # æœ€åˆã®2ã‚·ãƒ¼ãƒˆ
                    sheet = wb[sheet_name]
                    for row in list(sheet.iter_rows(max_row=20, values_only=True)):
                        row_text = " | ".join([str(cell) for cell in row if cell])
                        if row_text:
                            texts.append(row_text)
                wb.close()
                return "\n".join(texts)
            
            elif ext == '.pdf':
                try:
                    import fitz  # PyMuPDF
                    doc = fitz.open(file_path)
                    texts = []
                    for page_num in range(min(3, doc.page_count)):  # æœ€åˆã®3ãƒšãƒ¼ã‚¸
                        page = doc.load_page(page_num)
                        texts.append(page.get_text())
                    doc.close()
                    return "\n".join(texts)
                except ImportError:
                    return None
            
        except Exception as e:
            logging.warning(f"[FILE_CLASSIFIER] Content extraction failed: {e}")
        
        return None
